# LLM & cognitive-psychology Paper List

## LLM consistent with humans

1. Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation.
  
   https://arxiv.org/abs/2310.01320

   Agent for Avalon

2. EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus.

   https://arxiv.org/abs/2307.11760

   prompt里面加上“This is very important to my career” 可以增加reason的能力

3. War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars

   https://arxiv.org/pdf/2311.17227.pdf

   LLM agent, 模拟世界大战

 4. TURNING LARGE LANGUAGE MODELS INTO COGNI- TIVE MODELS

    https://arxiv.org/abs/2306.03917

    finetune llm on psychological experiment data, and turn it into the cognitive model. align better with human behavior, and can generalize to other cognitive tasks. (maybe have learned the cognitive pattern/ability)

5. Personality Traits in Large Language Models

   https://arxiv.org/abs/2307.00184

   根据心理测量学，llm具有稳定的个性。而且这些个性可以被有意识地改变。

6. ReAct: Synergizing Reasoning and Acting in Language Models

   https://arxiv.org/pdf/2210.03629.pdf

7. What makes Chain-of-Thought Prompting Effective? A Counterfactual Study

   https://aclanthology.org/2023.findings-emnlp.101.pdf

8. Language models and psychological sciences

   https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1279317/full

   Carefully evaluating LLMs with the tools of cognitive psychology will further understand the building blocks of the human mind.

9. Improving Factuality and Reasoning in Language Models through Multiagent Debate

    https://arxiv.org/abs/2305.14325

10. Large pre-trained language models contain human-like biases of what is right and wrong to do

    https://arxiv.org/abs/2103.11790

11. Capturing Failures of Large Language Models via Human Cognitive Biases

    http://arxiv.org/abs/2202.12299

12. Thought Cloning: Learning to Think while Acting by Imitating Human Thinking

    https://arxiv.org/pdf/2306.00323.pdf

    RL agent做下一个动作的时候考虑了thought

13. Think Twice: Perspective-Taking Improves Large Language Models’Theory-of-Mind Capabilities

    https://arxiv.org/pdf/2311.10227.pdf

14. Ask Again, Then Fail: Large Language Models' Vacillations in Judgement

    https://arxiv.org/pdf/2310.02174.pdf

    当面对挑战或误导信息时，LLMs经常会改变它们最初的正确判断，导致判断一致性下降

15. Learning From Mistakes Makes LLM Better Reasoner

    https://arxiv.org/pdf/2310.20689.pdf

16. Eliminating Reasoning via Inferring with Planning: A New Framework to Guide LLMs’ Non-linear Thinking

    https://arxiv.org/pdf/2310.12342.pdf

    LLM can own Non-linear Thinking like humans.

17. Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding

    https://arxiv.org/abs/2305.00633

    人类会通过将长形问题分解成子步骤来认知地解决问题，LLM可以通过问题分解的明确阶段和细致的反馈来提高其可信度

18. Re-Reading Improves Reasoning in Language Models

    https://arxiv.org/abs/2309.06275

    在prompt里加“read the question again: xxxx” 可以增加正确率

19. ADAPTING LARGE LANGUAGE MODELS VIA READING COMPREHENSION

    https://openreview.net/pdf?id=y886UXPEZ0

    预训练大模型的时候将data comprehensive read
    
20. How Large Language Models Implement Chain-of-Thought?

    https://openreview.net/pdf?id=b2XfOm3RJa

21. LARGE LANGUAGE MODELS CAN SELF-IMPROVE

    https://arxiv.org/pdf/2210.11610.pdf

    加了个voting 自己训练自己

22. Large Language Models as Analogical Reasoners

    https://arxiv.org/pdf/2310.01714.pdf


   

